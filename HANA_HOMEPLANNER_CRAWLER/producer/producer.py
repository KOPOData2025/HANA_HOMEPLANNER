import os
import time
import requests
import json
import sys
import logging
from datetime import datetime, timedelta
from apscheduler.schedulers.blocking import BlockingScheduler
from kafka import KafkaProducer
import redis
from logging.handlers import TimedRotatingFileHandler
from pymongo import MongoClient
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ==============================
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
# ==============================
KAFKA_BOOTSTRAP_SERVERS = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "localhost:9092")
KAFKA_TOPIC_NAME = os.getenv("KAFKA_TOPIC_NAME", "cheongyak.new_notice")
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))
REDIS_TTL = int(os.getenv("REDIS_TTL", "2592000"))
MONGO_URI = os.getenv("MONGO_URI", "")
MONGO_DB_NAME = os.getenv("MONGO_DB_NAME", "home_planner")
MONGO_COLLECTION_DATA = os.getenv("MONGO_COLLECTION_DATA", "applyhome_data")

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ í™•ì¸ ë¡œê·¸
print("=" * 50)
print("ğŸ”§ Producer í™˜ê²½ë³€ìˆ˜ ë¡œë“œ í™•ì¸")
print("=" * 50)
print(f"KAFKA_BOOTSTRAP_SERVERS: {KAFKA_BOOTSTRAP_SERVERS}")
print(f"KAFKA_TOPIC_NAME: {KAFKA_TOPIC_NAME}")
print(f"REDIS_HOST: {REDIS_HOST}")
print(f"REDIS_PORT: {REDIS_PORT}")
print(f"REDIS_TTL: {REDIS_TTL}")
print(f"MONGO_URI: {MONGO_URI}")
print(f"MONGO_DB_NAME: {MONGO_DB_NAME}")
print(f"MONGO_COLLECTION_DATA: {MONGO_COLLECTION_DATA}")
print("=" * 50)

## DB ì—°ê²°
client = MongoClient(MONGO_URI)
db = client[MONGO_DB_NAME]
collection = db[MONGO_COLLECTION_DATA]

# ==============================
# ë¡œê·¸ ì„¤ì •
# ==============================
LOG_FILE = "scheduler.log"

# í¬ë§· ì„¤ì •
log_formatter = logging.Formatter(
    "%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S"
)

# ì½˜ì†” ë¡œê·¸ í•¸ë“¤ëŸ¬
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setFormatter(log_formatter)

# íŒŒì¼ ë¡œê·¸ í•¸ë“¤ëŸ¬ (ë§¤ì¼ íšŒì „)
file_handler = TimedRotatingFileHandler(LOG_FILE, when="midnight", interval=1, encoding="utf-8")
file_handler.suffix = "%Y-%m-%d"
file_handler.setFormatter(log_formatter)

# ë£¨íŠ¸ ë¡œê±° ì„¤ì •
logging.basicConfig(level=logging.INFO, handlers=[console_handler, file_handler])
logger = logging.getLogger(__name__)

# ==============================
# Kafka ì„¤ì •
# ==============================
producer = KafkaProducer(
    bootstrap_servers=[KAFKA_BOOTSTRAP_SERVERS],
    value_serializer=lambda v: json.dumps(v, ensure_ascii=False).encode('utf-8'),
)

# ==============================
# Redis ì„¤ì •
# ==============================
try:
    r = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0, decode_responses=True)
    r.ping()
    logger.info("âœ… Redis ì—°ê²° ì„±ê³µ")
except Exception as e:
    logger.error(f"âŒ Redis ì—°ê²° ì‹¤íŒ¨: {e}")
    sys.exit(1)

# ==============================
# ì²­ì•½í™ˆ API ì„¤ì •
# ==============================
API_URL = "https://api.odcloud.kr/api/ApplyhomeInfoDetailSvc/v1/getAPTLttotPblancDetail"
SERVICE_KEY = os.getenv("CHEONGYAK_SERVICE_KEY", "")


def get_date_range():
    """ì˜¤ëŠ˜ ~ í•œ ë‹¬ í›„ ë‚ ì§œ ë²”ìœ„ ë°˜í™˜"""
    today = datetime.now()
    one_month_later = today + timedelta(days=30)
    return today.strftime("%Y-%m-%d"), one_month_later.strftime("%Y-%m-%d")


def is_new_notice(notice_id: str) -> bool:
    """Redisì— notice_id ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ì €ì¥"""
    if not notice_id:
        return False
    key = f"notice:{notice_id}"
    if r.exists(key):
        return False  # ì´ë¯¸ ì¡´ì¬í•¨
    r.set(key, 1, ex=REDIS_TTL)
    return True


def fetch_notices():
    """ì²­ì•½í™ˆ API í˜¸ì¶œ"""
    start_date, end_date = get_date_range()
    params = {
        "page": 1,
        "perPage": 100,
        "serviceKey": SERVICE_KEY,
        "cond[RCRIT_PBLANC_DE::GTE]": start_date,
        "cond[RCRIT_PBLANC_DE::LTE]": end_date,
    }

    res = requests.get(API_URL, params=params, timeout=15)
    res.raise_for_status()
    data = res.json()
    return data.get("data", [])


def check_and_publish():
    """ìƒˆ ê³µê³  ê°ì§€ í›„ Kafka ë°œí–‰"""
    start_date, end_date = get_date_range()
    logger.info(f"ğŸ• ì²­ì•½í™ˆ ìƒˆ ê³µê³  ê°ì‹œ ì¤‘... (ë²”ìœ„: {start_date} ~ {end_date})")

    try:
        notices = fetch_notices()
        new_count = 0
        for n in notices:
            notice_id = n.get("HOUSE_MANAGE_NO")
            
            # âœ… Redis ì¤‘ë³µ í™•ì¸
            if is_new_notice(notice_id):
                new_count += 1
                # âœ… 1. applyhome_dataì— raw ë°ì´í„° ì €ì¥
                n["_id"] = notice_id
                collection.update_one({"_id": notice_id}, {"$set": n}, upsert=True)
                logger.info(f"ğŸ“¦ MongoDB ì €ì¥ ì™„ë£Œ: {notice_id}")

                # âœ… 2. Kafka ë°œí–‰ (ì¢Œí‘œ ê³„ì‚°ìš© ë°ì´í„°ë§Œ)
                producer.send(KAFKA_TOPIC_NAME, value={
                    "notice_id": notice_id,
                    "region": n.get("HSSPLY_ADRES"),
                    "title": n.get("HOUSE_NM"),
                    "url": f"https://www.applyhome.co.kr/ai/aia/selectAPTLttotPblancDetail.do?houseManageNo={notice_id}&pblancNo={notice_id}"
                })

        if new_count == 0:
            logger.info("â„¹ï¸ ìƒˆë¡œìš´ ê³µê³  ì—†ìŒ.")
        else:
            producer.flush()
            logger.info(f"âœ… Kafkaì— {new_count}ê±´ ë°œí–‰ ì™„ë£Œ.")

    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)


# ==============================
# ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
# ==============================
scheduler = BlockingScheduler(timezone="Asia/Seoul")
scheduler.add_job(check_and_publish, 'interval', minutes=5, id='notice_polling')


def graceful_shutdown():
    """Kafka Producer ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì•ˆì „ ì¢…ë£Œ"""
    logger.info("ğŸ›‘ ì¢…ë£Œ ì‹ í˜¸ ê°ì§€! Kafka Producer ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ ì¤‘...")
    try:
        if scheduler.running:
            scheduler.shutdown(wait=False)
            logger.info("ğŸ•“ ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ ì™„ë£Œ.")
    except Exception:
        pass

    try:
        producer.flush()
        producer.close()
        logger.info("ğŸ’¾ Kafka Producer ì¢…ë£Œ ì™„ë£Œ.")
    except Exception:
        pass

    logger.info("ğŸ‘‹ í”„ë¡œê·¸ë¨ì´ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    sys.exit(0)


# ==============================
# ë©”ì¸ ì‹¤í–‰ë¶€
# ==============================
if __name__ == "__main__":
    logger.info("ğŸš€ ì²­ì•½í™ˆ ìƒˆ ê³µê³  ê°ì‹œ & Kafka ë°œí–‰ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")

    try:
        check_and_publish()  # ì¦‰ì‹œ 1íšŒ ì‹¤í–‰
        scheduler.start()
    except (KeyboardInterrupt, SystemExit):
        graceful_shutdown()
